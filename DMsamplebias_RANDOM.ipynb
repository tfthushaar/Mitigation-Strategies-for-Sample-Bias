{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6670967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in c:\\users\\thush\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from fairlearn) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from fairlearn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from fairlearn) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thush\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620bf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fairlearn.metrics import demographic_parity_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941e8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d18f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "data = pd.read_csv(url, names=columns, na_values=\" ?\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fad58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data\n",
    "data_cleaned = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237ebfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to dummy variables\n",
    "data_encoded = pd.get_dummies(data_cleaned, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a53e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before sampling:\n",
      "income_>50K\n",
      "False    24720\n",
      "True      7841\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class balance before sampling\n",
    "print(f'Class distribution before sampling:\\n{data_encoded[\"income_>50K\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608291d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random sampling to get a subset of the data\n",
    "sampled_data = data_encoded.sample(frac=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48298e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after sampling:\n",
      "income_>50K\n",
      "False    12356\n",
      "True      3924\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class balance after sampling\n",
    "print(f'Class distribution after sampling:\\n{sampled_data[\"income_>50K\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a06b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = sampled_data.drop('income_>50K', axis=1)\n",
    "y = sampled_data['income_>50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae4331f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sampled data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b72e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c91304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7920761670761671\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ba72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference (Sex): 5.36%\n",
      "Demographic Parity Difference (Race): 11.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thush\\AppData\\Local\\Temp\\ipykernel_10512\\87556705.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sensitive_features_test['race'] = sensitive_features_test[['race_Asian-Pac-Islander', 'race_Black', 'race_Other', 'race_White']].idxmax(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Define the sensitive features in the test set\n",
    "sensitive_features_test = X_test[['sex_Male', 'race_Asian-Pac-Islander', 'race_Black', 'race_Other', 'race_White']]\n",
    "\n",
    "# Calculate demographic parity difference for sex\n",
    "dp_difference_sex = demographic_parity_difference(y_test, y_pred_binary, sensitive_features=sensitive_features_test['sex_Male'])\n",
    "print(f\"Demographic Parity Difference (Sex): {dp_difference_sex * 100:.2f}%\")\n",
    "\n",
    "# Calculate demographic parity difference for race\n",
    "# Combine one-hot encoded race columns into a single race column for demographic parity calculation\n",
    "sensitive_features_test['race'] = sensitive_features_test[['race_Asian-Pac-Islander', 'race_Black', 'race_Other', 'race_White']].idxmax(axis=1)\n",
    "dp_difference_race = demographic_parity_difference(y_test, y_pred_binary, sensitive_features=sensitive_features_test['race'])\n",
    "print(f\"Demographic Parity Difference (Race): {dp_difference_race * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
